{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aprendizaje supervisado: cada observación tiene una respuesta asociada que guía el aprendizaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "df  = pd.read_csv(\"data/titanic.csv\")\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contexto y problema\n",
    "Definir un problema en Machine Learning o Aprendizaje Automático requiere de una serie de pasos hasta llegar a una conclusión que defina un problema a resolver. En este caso no se trata de un problema real o necesidad que una empresa debería resolver para mejorar las decisones que elige ni tampoco anticipar como se encotrará en el futuro, sino más bien se trata de un ejemplo sobre como implementar y traducir los distintos componentes de un problema didáctico al Machine Learning. Entonces, introduciendonos en este ejemplo podemos definir a una variable objetivo, es decir el elemento de interés que nuestro modelo va a tener estudiar lo mejor posible, como los supervivientes del hundimiento del Titanic('Survived') y a las variables predictoras, es decir las características que ayudarán al modelo a realizar sus predicciones, como el resto del conjunto('Age','Pclass',etc), de esta manera concluimos que se considera un problema de clasficación binaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputación de datos faltantes mediante medias y modas\n",
    "\n",
    "df.fillna({\"Age\":df[\"Age\"].mean()},inplace=True)\n",
    "\n",
    "mode = df[\"Embarked\"].mode()\n",
    "df.fillna({\"Embarked\":mode[0]},inplace=True)\n",
    "\n",
    "# codificando variables categóricas nominales\n",
    "\n",
    "df[\"Sex_encoded\"] = LabelEncoder().fit_transform(df[\"Sex\"])\n",
    "\n",
    "# a su vez generamos una versión textual de la variable binaria objetivo\n",
    "\n",
    "map_survived = {\n",
    "    0:\"no\",\n",
    "    1:\"yes\"\n",
    "}\n",
    "df[\"Survived_no_encoded\"] = df[\"Survived\"].apply(lambda x : map_survived.get(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable Categóricas y Datasets Desbalanceados\n",
    "La función de las variables categóricas es brindar información clasificando las observaciones, puenden demostrar una influencia en los datos permitiendonos determinar comportamientos o sacar conclusiones premeditadas si los datos influyen en estas. Los tipos de variables categóricas que hay son nominales: aquellas que actúan como etiquetas de los objetos(dentro de estas pueden encontrarse las que se dividen en 2 clases y su codificación las convierte en binarias, es decir, valores posibles de 0 o 1) y ordinales: aquellas que representan un órden jerárquico en particular que rige en las observaciones.\n",
    "\n",
    "En algunos casos los Datasets tienden a contener más cantidades de datos categóricos que otros, esto puede llegar a traer problemas la hora de entrenar un modelo o evaluar el desempeño de este debido a que la variable minoritaria tiende a ser ignorada y genera un sesgo en cuanto a la importancia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survived_counts = df[\"Survived_no_encoded\"].value_counts().reset_index()\n",
    "survived_counts.columns = [\"survived\",\"count\"]\n",
    "\n",
    "fig = px.bar(survived_counts, x=\"survived\", y=\"count\", title='Conteo de Sobrevivientes')\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CART(classification and regression trees)\n",
    "algoritmos basados en utilizar umbrales que condicionen el destino de una variable, pero no cualquier umbral, sino aquellos que dependiendo la problemática en cestión(en este caso de clasificación) obtengan el menor valor en cuanto a la probabilidad de clasificar mal la variable objetivo o grado de aleatoriedad del umbral, se realizan repetidas pruebas de este tipo y se determian los umbrales óptimos del modelo. Otra de las características es que se modifica el volumen, es decir, la cantidad de particiones que tendrá el modelo, siendo denominado criterio de parada como el término utilizado. Para ello, hay parámetros que reciben valores y representan cierta particularidad de tamaño como la distancia que habrá entre el nodo(condición) inicial y la última hoja(valor asociado) o la suma mínima de pesos de instancia necesaria en un elemento secundario. Dependiendo de los valores que se les otorguen, el árbol predictor sufrirá de un crecimiento o reducción en cuanto a su complejidad y evitando el sobreajuste en este último caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seccionamos los datos en grupos de entrenamiento y prueba\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "                                                   df[[\"Sex_encoded\",\"Pclass\",\"Fare\",\"Parch\",\"SibSp\"]],\n",
    "                                                   df[\"Survived\"],\n",
    "                                                   test_size=0.12)\n",
    "\n",
    "# declaración del algoritmo\n",
    "\n",
    "tree_decision = tree.DecisionTreeClassifier(criterion=\"entropy\", # medida de aleatoriedad, determinará los nodos del modelo en base a la probabilidad de clasificar erroneamente una variable, pero sin darle mayor importancias a ciertas características\n",
    "                                           max_depth=6, # distancia entre el nodo(condición) principal y la última hoja(respuesta asociada), valores recomendados: 3-10\n",
    "                                           min_samples_split=6, # mínimo número de muestras requeridas para dividir un nodo, valores recomendados: 2-10\n",
    "                                           min_samples_leaf=5, #  mínimo número de muestras requeridas en cada hoja, valores recomendados: 1-10\n",
    "                                           ccp_alpha=0.003) # valor de post-poda(luego de que el modelo se ajute) que evita el sobreajuste \n",
    "\n",
    "model = tree_decision.fit(x_train, y_train)\n",
    "\n",
    "# predicción de los datos de prueba\n",
    "\n",
    "class_predicts = model.predict(x_test)\n",
    "\n",
    "class_real = y_test.values\n",
    "\n",
    "# Matriz de confusión: recolecta los aciertos y desaciertos tanto de la clase postiva como negativa del modelo\n",
    "\n",
    "matrix_confusion = confusion_matrix(class_real,class_predicts)\n",
    "TP = matrix_confusion[0,0]\n",
    "FP = matrix_confusion[0,1]\n",
    "FN = matrix_confusion[1,0]\n",
    "TN = matrix_confusion[1,1]\n",
    "\n",
    "# Accuracy: indica la acertividad general de nuestro modelo con respecto a las nuevas observaciones\n",
    "\n",
    "accuracy = accuracy_score(class_real, class_predicts)\n",
    "color_accuracy = \"green\"\n",
    "if accuracy < 0.6:\n",
    "    color_accuracy = \"red\"\n",
    "accuracy_str = str(accuracy)\n",
    "\n",
    "# Recall: es utilizada para poder saber la efectividad de nuestro modelo a la hora de predecir valores de la clase positiva\n",
    "\n",
    "recall = recall_score(class_real, class_predicts)\n",
    "color_recall = \"green\"\n",
    "if recall < 0.6:\n",
    "    color_recall = \"red\"\n",
    "recall_str = str(recall)\n",
    "\n",
    "# Precision: es utilizada para poder saber que porcentage de valores que fueron clasificados como positivos son realmente positivos\n",
    "\n",
    "precision = precision_score(class_real, class_predicts)\n",
    "color_precision = \"green\"\n",
    "if precision < 0.6:\n",
    "    color_precision = \"red\"\n",
    "precision_str = str(precision)\n",
    "\n",
    "# F1 Score: es utilizada como un resumen de las dos últimas metricas\n",
    "\n",
    "F1_score = f1_score(class_real, class_predicts)\n",
    "color_f1 = \"green\"\n",
    "if F1_score < 0.6:\n",
    "    color_f1 = \"red\"\n",
    "F1_score_str = str(F1_score)\n",
    "\n",
    "print(tree.export_text(model, feature_names=[\"Sex_encoded\",\"Pclass\",\"Fare\",\"Parch\",\"SibSp\"]))\n",
    "\n",
    "plt.figure(figsize=(35,22))\n",
    "tree.plot_tree(model, feature_names=[\"Sex_encoded\",\"Pclass\",\"Fare\",\"Parch\",\"SibSp\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dashboard que muestra las probabilidades de sobrevivir según las variables y el desempeño del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x2bdf53bf920>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# creación de dashboard\n",
    "\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "app.layout = html.Div(id=\"body\",className=\"e1_body\",children=[\n",
    "html.H1(\"Titanic\",id=\"title\",className=\"e1_title\"),\n",
    "html.Div(className=\"e1_dashboards\",children=[\n",
    "    html.Div(id=\"graph_div_1\",className=\"e1_graph_div\",children=[\n",
    "        html.Div(id=\"dropdown_div_1\",className=\"e1_dropdown_div\",children=[\n",
    "            dcc.Dropdown(id=\"dropdown_1\",className=\"e1_dropdown\",\n",
    "                        options = [\n",
    "                            {\"label\":\"Sexo\",\"value\":\"Sex\"},\n",
    "                            {\"label\":\"Clase social\",\"value\":\"Pclass\"},\n",
    "                            {\"label\":\"Embarcadero\",\"value\":\"Embarked\"},\n",
    "                            {\"label\":\"Padres e hijos/as\",\"value\":\"Parch\"},\n",
    "                            {\"label\":\"Hermanas/os y esposas/os\",\"value\":\"SibSp\"},\n",
    "                        ],\n",
    "                        value=\"Sex\",\n",
    "                        multi=False,\n",
    "                        clearable=False)\n",
    "        ]),\n",
    "        dcc.Graph(id=\"piechart\",className=\"e1_graph\",figure={})\n",
    "    ]),\n",
    "    html.Div(id=\"graph_div_2\",className=\"e1_graph_div\",children=[\n",
    "        html.Div(id=\"dropdown_div_2\",className=\"e1_dropdown_div\",children=[\n",
    "            dcc.Dropdown(id=\"dropdown_2\",className=\"e1_dropdown\",\n",
    "                        options = [\n",
    "                            {\"label\":\"Edad\",\"value\":\"Age\"},\n",
    "                            {\"label\":\"Boleto\",\"value\":\"Fare\"},\n",
    "                        ],\n",
    "                        value=\"Age\",\n",
    "                        multi=False,\n",
    "                        clearable=False)\n",
    "        ]),\n",
    "        dcc.Graph(id=\"bar\",className=\"e1_graph\",figure={})\n",
    "    ]),\n",
    "]),\n",
    "    \n",
    "    html.Div(className=\"e1_div\", children=[\n",
    "        html.Div(id=\"performance\", className=\"e1_performance\",children=[\n",
    "            html.P([html.B(\"Clases reales\", style={\"color\":\"blue\"}),\"   |   \",html.B(\"Predicciones\",style={\"color\":\"red\"})], style={\"text-align\":\"center\",\"font-family\":\"sans-serif\"}),\n",
    "            html.P(\"--------------------------------------------------------------------------------------------------------------------------------------\",style={\"margin\":\"0\"}),\n",
    "            html.P(f\"{class_real}\", className=\"e1_real_class\"),\n",
    "            html.P(f\"{class_predicts}\", className=\"e1_predicts\")\n",
    "        ]),\n",
    "        html.Div(id=\"metrics\", className=\"e1_metrics\", children=[\n",
    "                html.P(\"Matriz de confusión\", style={\"font-size\":\"0.9em\",\"text-align\":\"center\",\"font-family\":\"sans-serif\",\"font-weigth\":\"bold\"}),\n",
    "                html.Div(id=\"matrix\", className=\"e1_matrix\", children=[\n",
    "                html.Div([html.B(TP,style={\"color\":\"green\",\"font-family\":\"sans-serif\"})],id=\"TP\",className=\"e1_successes\"), \n",
    "                html.Div([html.B(FP,style={\"color\":\"red\",\"font-family\":\"sans-serif\"})],id=\"FP\",className=\"e1_mistakes\"),\n",
    "                html.Div([html.B(FN,style={\"color\":\"red\",\"font-family\":\"sans-serif\"})],id=\"FN\",className=\"e1_mistakes\"),\n",
    "                html.Div([html.B(TN,style={\"color\":\"green\",\"font-family\":\"sans-serif\"})],id=\"TN\",className=\"e1_successes\")\n",
    "                ]),\n",
    "                html.Div(id=\"scores\",children=[\n",
    "                html.Ul(id=\"list\",children=[\n",
    "                html.Li([f\"Accuracy: \",html.B(accuracy_str[:4],style={\"color\":f\"{color_accuracy}\"})],id=\"accuracy\",className=\"e1_score\"),\n",
    "                html.Li([f\"Recall: \",html.B(recall_str[:4],style={\"color\":f\"{color_recall}\"})],id=\"recall\",className=\"e1_score\"),\n",
    "                html.Li([f\"Precision: \",html.B(precision_str[:4],style={\"color\":f\"{color_precision}\"})],id=\"precision\",className=\"e1_score\"),\n",
    "                html.Li([f\"F1 Score: \",html.B(F1_score_str[:4],style={\"color\":f\"{color_f1}\"})],id=\"f1_score\",className=\"e1_score\")\n",
    "                ])\n",
    "                \n",
    "            ])\n",
    "        ])\n",
    "    ])\n",
    "])\n",
    "\n",
    "# generan interacción entre los datos de entrada y los elementos que serán modificados \n",
    "\n",
    "@app.callback(\n",
    "    [Output(component_id=\"piechart\",component_property=\"figure\"),\n",
    "    Output(component_id=\"bar\",component_property=\"figure\")],\n",
    "    [Input(component_id=\"dropdown_1\",component_property=\"value\"),\n",
    "    Input(component_id=\"dropdown_2\",component_property=\"value\")]\n",
    ")\n",
    "\n",
    "# función que se ejecuta cada vez que se interactúa con los elementos \n",
    "\n",
    "def update_graph(slct_var_cat,slct_var_num):\n",
    "    \n",
    "    df_percentage = df.groupby(slct_var_cat)[\"Survived\"].mean().reset_index()\n",
    "    df_percentage[\"Survived\"] = round(df_percentage[\"Survived\"] * 100)\n",
    "    df_percentage[\"Survived\"] = df_percentage[\"Survived\"].astype(str)\n",
    "    df_percentage[\"var_percentage\"] = df_percentage[slct_var_cat].astype(str)+\"(\"+df_percentage[\"Survived\"]+\"%)\"\n",
    "    \n",
    "    piechart = px.pie(df_percentage, values=\"Survived\", names=\"var_percentage\", title=\"Probabilidad de supervivencia\")\n",
    "    \n",
    "    df_mean = df.groupby(\"Survived_no_encoded\")[slct_var_num].mean().reset_index()\n",
    "    \n",
    "    barplot = px.bar(df_mean, x=\"Survived_no_encoded\", y=slct_var_num, title=\"Medias de Edad y Boleto\",labels={\"x\":\"sobrevivientes\",\"y\":slct_var_num})\n",
    "    barplot.update_layout(xaxis_title=\"Sobrevivientes\")\n",
    "    \n",
    "    return piechart,barplot\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run_server(debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error de varianza\n",
    "\n",
    "es la variabilidad que existe en la función objetivo con respecto a los diferentes datos de entrenamiento que se utilicen para la creación del modelo, sucede principalmente en algoritmos que se ajustan fácilmente a los datos y requieren menos suposiciones a diferencia de los algoritmos con alto bías, algunos ejemplos de algoritmos con alta variranza son: KNN, CART o Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "bucle = list(range(14))\n",
    "\n",
    "for i in bucle:\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "                                                   df[[\"Sex_encoded\",\"Pclass\",\"Fare\",\"Parch\",\"SibSp\"]],\n",
    "                                                   df[\"Survived\"],\n",
    "                                                   test_size=0.25)\n",
    "    class_real = y_test.values\n",
    "    class_predicts = model.predict(x_test)\n",
    "    accuracy = accuracy_score(class_real, class_predicts)\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "plt.plot(bucle, accuracies, marker=\"*\", c=\"r\")\n",
    "plt.grid(\"on\")\n",
    "plt.title(\"Error de Varianza\")\n",
    "plt.ylabel(\"Acuracies\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
